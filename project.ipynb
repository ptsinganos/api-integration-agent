{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0db2a27",
   "metadata": {},
   "source": [
    "# Hands-on project: Build a Coding Agent  \n",
    "\n",
    "In this notebook, you can practice what you've learned in the course videos by **building your own coding agent**. \n",
    "\n",
    "You'll build this agent step-by-step, defining the tools it needs and implementing the agent loop that lets it reason through tasks.\n",
    "\n",
    "You can write code by hand if you wish, but this project item includes access to a chatbot built right into the Jupyter notebook, which you can ask for help or instruct to write code for you. \n",
    "\n",
    "> ‚ö†Ô∏è **Important:** Your workspace session lasts 2 hours. Remember to download `project.ipynb` periodically to save your progress!\n",
    "\n",
    "## üìö About the Project\n",
    "\n",
    "You'll build an agent that autonomously generates and executes code in a secure cloud sandbox to respond to user queries.\n",
    "\n",
    "Here's the fun part - **you get to design the agent yourself!** Maybe your agent specializes in data analysis and visualizations. Or maybe it builds small web apps, like a calculator widget. The choice is yours!\n",
    "\n",
    "<details>\n",
    "<summary><strong>Your project should include</strong></summary>\n",
    "\n",
    "- A function that accepts a user query as input\n",
    "- Tool functions with schemas that the LLM can call (like execute_code)\n",
    "- Code that handles conversation memory and the **agent loop** described in the \"Inside a coding agent\" video\n",
    "- Access to an E2B sandbox to enable safe code execution\n",
    "\n",
    "</details>\n",
    "\n",
    "For the two example agents mentioned above, here's what the final product might look like:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"50%\" valign=\"top\">\n",
    "<strong>üìä Data Analyzer Agent</strong><br/>\n",
    "Generates synthetic datasets, performs statistical analysis, and creates visualizations\n",
    "<br/><br/>\n",
    "<img src=\"images/histogram.png\" width=\"90%\" style=\"max-height: 300px; object-fit: contain;\" alt=\"Data Analyzer Output\" />\n",
    "</td>\n",
    "<td width=\"50%\" valign=\"top\">\n",
    "<strong>üåê Web Builder Agent</strong><br/>\n",
    "Creates interactive web applications with HTML, CSS, and JavaScript\n",
    "<br/><br/>\n",
    "<img src=\"images/calculator_app.png\" width=\"90%\" style=\"max-height: 300px; object-fit: contain;\" alt=\"Calculator App Output\" />\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "## Your project workflow\n",
    "\n",
    "To build your coding agent, you'll carry out the following workflow:\n",
    "1. **Tool calling** üõ†Ô∏è ‚Äî define tool schemas and functions to help your agent interact with files\n",
    "2. **Agent loop** üîÑ ‚Äî build the iterative loop that let's your agent work through your task\n",
    "3. **Sandbox execution** ‚òÅÔ∏è ‚Äî give your agent access to an E2B sandbox\n",
    "\n",
    "```\n",
    "\n",
    "           [ Specify tools üõ†Ô∏è ]\n",
    "                   |\n",
    "                   v\n",
    "          [ Implement agent loop üîÑ ]\n",
    "                   |\n",
    "                   v\n",
    "        [ Set up sandbox execution ‚òÅÔ∏è ]\n",
    "```\n",
    "## üí° Tips for completing the project\n",
    "\n",
    "This project space includes access to a chatbot that can assist you as your work on your coding agent. \n",
    "\n",
    "To open Jupyter chat, click on the chat bubble icon on the left sidebar of Jupyter Lab:\n",
    "\n",
    "  <img src=\"images/jupyter_chat_bordered.png\" width=\"150\" style=\"vertical-align: middle;\">\n",
    "\n",
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p><summary><strong>üóÇÔ∏è Reminder: Attach context to every chatbot prompt</strong></summary>\n",
    "\n",
    "<p>When you ask the chatbot for help, always upload these files so it has full project context:\n",
    "\n",
    "- `project.ipynb`: shares your latest code and notebook state\n",
    "- `docs.md`: E2B + OpenAI documentation (linked in the next section)</p>\n",
    "\n",
    "<p>Bringing all context keeps responses grounded in what you've built and E2B capabilities.</p>\n",
    "\n",
    "<p>**Debugging tip:** When troubleshooting issues, share error messages and relevant code snippets with the chatbot. Follow iterative debugging practices‚Äîtest small changes, verify outputs, and use the AI assistant to help diagnose problems step by step.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2d88a1",
   "metadata": {},
   "source": [
    "# Step 1: üõ†Ô∏è Tool Calling\n",
    "\n",
    "It's time to define the tools your agent can use! Every tool extends what your agent can do‚Äîfrom executing code to manipulating files.\n",
    "\n",
    "- üéØ **Goal:** Create function schemas that tell the LLM what tools are available and how to call them\n",
    "- üîÅ **Workflow:** Think about what tools your agent needs (like execute_code for running Python, or write_file for creating files), then implement their schemas and execution logic\n",
    "- üí° **Remember:** Tools are called by the LLM via function calling, so schemas must be precise\n",
    "- üí° **Tip:** Use the JupyterAI chatbot with the **prompt examples below**\n",
    "- üìé **Attach these files:** `project.ipynb` and `docs.md` when asking the chatbot for help\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Your tool system should include:\n",
    "\n",
    "- ‚úì Function schemas that describe each tool's name, description, and parameters\n",
    "- ‚úì Implementation functions that execute the actual tool logic\n",
    "- ‚úì An executor handler that routes LLM tool calls to implementations\n",
    "- ‚úì Error handling for invalid tool calls or execution failures\n",
    "\n",
    "---\n",
    "\n",
    "<details>\n",
    "<summary><strong>üìö Refresher: Function Schema Pattern (click to expand)</strong></summary>\n",
    "\n",
    "Every tool needs three components:\n",
    "\n",
    "1. **Schema** - JSON object describing the function signature for the LLM\n",
    "2. **Implementation** - Python function that executes the tool\n",
    "3. **Executor** - Handler that routes LLM tool calls to implementations\n",
    "\n",
    "**Schema Structure:**\n",
    "```python\n",
    "{\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"execute_code\",\n",
    "    \"description\": \"Execute Python code and return result\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"code\": {\"type\": \"string\", \"description\": \"Python code\"}\n",
    "        },\n",
    "        \"required\": [\"code\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Why function calling?**\n",
    "- Gives the LLM structured ways to interact with your system\n",
    "- Ensures type safety and validation\n",
    "- Enables the LLM to use tools autonomously during reasoning\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>üìö Refresher: Tool Components (click to expand)</strong></summary>\n",
    "\n",
    "**Implementation function:**\n",
    "```python\n",
    "def execute_code(code: str) -> dict:\n",
    "    # Execute the code and capture output\n",
    "    # Return dict with \"results\" and \"errors\" keys\n",
    "    pass\n",
    "```\n",
    "\n",
    "**Executor function:**\n",
    "```python\n",
    "def execute_tool(name: str, args: str, tools: dict) -> dict:\n",
    "    # Parse JSON args\n",
    "    # Look up tool by name\n",
    "    # Call tool function with args\n",
    "    # Handle errors gracefully\n",
    "    pass\n",
    "```\n",
    "\n",
    "**Tools dictionary:**\n",
    "```python\n",
    "tools = {\n",
    "    \"execute_code\": execute_code,\n",
    "    \"write_file\": write_file,\n",
    "    # ... more tools\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "<details>\n",
    "<summary><strong>üìä Prompt Example ‚Äî Data Analyzer Tools (click to expand)</strong></summary>\n",
    "\n",
    "```\n",
    "You are my coding assistant. Generate Python code to define the tool calling system for my Data Analyzer Agent.\n",
    "Return code only-no explanations, comments, or markdown.\n",
    "\n",
    "Requirements:\n",
    "1. Import warnings and suppress warnings with warnings.filterwarnings('ignore')\n",
    "2. Import sys, StringIO, json, and Callable from typing\n",
    "3. Import OpenAI from openai\n",
    "4. Initialize client = OpenAI()\n",
    "5. Define execute_code(code: str) -> dict function that runs code locally using exec() and captures stdout\n",
    "6. Define execute_code_schema as dict with type, name, description, and parameters\n",
    "7. Define tools dict mapping \"execute_code\" to the function\n",
    "8. Define execute_tool(name: str, args: str, tools: dict) that parses JSON args and calls the tool\n",
    "9. Handle errors gracefully (JSONDecodeError, KeyError, Exception) and return error messages\n",
    "10. Return execution dict with \"results\" and \"errors\" keys\n",
    "\n",
    "**Attachments:**\n",
    "- `docs.md` for E2B + OpenAI documentation\n",
    "- `project.ipynb` to see the progress of my project\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>üåê Prompt Example ‚Äî Web Builder Tools (click to expand)</strong></summary>\n",
    "\n",
    "```\n",
    "You are my coding assistant. Generate Python code to define the tool calling system for my Web Builder Agent.\n",
    "Return code only-no explanations, comments, or markdown.\n",
    "\n",
    "Requirements:\n",
    "1. Import warnings and suppress warnings with warnings.filterwarnings('ignore')\n",
    "2. Import sys, StringIO, json, os, and Callable from typing\n",
    "3. Import OpenAI from openai\n",
    "4. Initialize client = OpenAI()\n",
    "5. Define execute_code(code: str) -> dict that runs Python code locally\n",
    "6. Define write_file(content: str, file_path: str) -> dict that writes content to file and creates directories if needed\n",
    "7. Define execute_code_schema and write_file_schema as function schema dicts\n",
    "8. Create tools dict mapping \"execute_code\" and \"write_file\" to their functions\n",
    "9. Define execute_tool(name: str, args: str, tools: dict) handler with error handling\n",
    "10. Handle JSONDecodeError, KeyError, PermissionError, and general exceptions\n",
    "\n",
    "**Attachments:**\n",
    "- `docs.md` for E2B + OpenAI documentation\n",
    "- `project.ipynb` to see the progress of my project\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>üåê Prompt Example ‚ÄîAPI Integration Tools (click to expand)</strong></summary>\n",
    "\n",
    "```\n",
    "You are my coding assistant. Generate Python code to define the tool calling system for my API Integration Agent.\n",
    "Return code only-no explanations, comments, or markdown.\n",
    "\n",
    "Requirements:\n",
    "1. Import warnings and suppress warnings with warnings.filterwarnings('ignore')\n",
    "2. Import sys, StringIO, json, os, and Callable from typing\n",
    "3. Import OpenAI from openai\n",
    "4. Initialize client = OpenAI()\n",
    "5. Define execute_code(code: str) -> dict function that runs code locally using exec() and captures stdout\n",
    "6. Define write_file(content: str, file_path: str) -> dict that writes content to file and creates directories if needed\n",
    "8. Define execute_code_schema and write_file_schema as function schema dicts\n",
    "9. Create tools dict mapping \"execute_code\" and \"write_file\" to their functions\n",
    "10. Define execute_tool(name: str, args: str, tools: dict) handler with error handling\n",
    "11. Handle JSONDecodeError, KeyError, PermissionError, and general exceptions\n",
    "\n",
    "**Attachments:**\n",
    "- `docs.md` for E2B + OpenAI documentation\n",
    "- `project.ipynb` to see the progress of my project\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "393a927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "from io import StringIO\n",
    "import json\n",
    "import os\n",
    "from typing import Callable\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def execute_code(code: str) -> dict:\n",
    "    execution = {\"results\": [], \"errors\": []}\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = StringIO()\n",
    "    try:\n",
    "        exec(code)\n",
    "        output = sys.stdout.getvalue()\n",
    "        execution[\"results\"].append(output)\n",
    "    except Exception as e:\n",
    "        execution[\"errors\"].append(str(e))\n",
    "    finally:\n",
    "        sys.stdout = old_stdout\n",
    "    return execution\n",
    "\n",
    "def write_file(content: str, file_path: str) -> dict:\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content)\n",
    "        return {\"results\": [f\"File written to {file_path}\"], \"errors\": []}\n",
    "    except PermissionError as e:\n",
    "        return {\"results\": [], \"errors\": [f\"Permission denied: {str(e)}\"]}\n",
    "    except Exception as e:\n",
    "        return {\"results\": [], \"errors\": [str(e)]}\n",
    "\n",
    "execute_code_schema = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"execute_code\",\n",
    "    \"description\": \"Execute Python code and return the output or errors\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"code\": {\"type\": \"string\", \"description\": \"Python code to execute\"}\n",
    "        },\n",
    "        \"required\": [\"code\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "write_file_schema = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"write_file\",\n",
    "    \"description\": \"Write content to a file path, creating directories if needed\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"content\": {\"type\": \"string\", \"description\": \"File content\"},\n",
    "            \"file_path\": {\"type\": \"string\", \"description\": \"Path to save the file\"}\n",
    "        },\n",
    "        \"required\": [\"content\", \"file_path\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "tools = {\n",
    "    \"execute_code\": execute_code,\n",
    "    \"write_file\": write_file\n",
    "}\n",
    "\n",
    "def execute_tool(name: str, args: str, tools: dict[str, Callable]) -> dict:\n",
    "    try:\n",
    "        parsed_args = json.loads(args)\n",
    "        if name not in tools:\n",
    "            return {\"error\": f\"Tool {name} not found.\"}\n",
    "        return tools[name](**parsed_args)\n",
    "    except json.JSONDecodeError as e:\n",
    "        return {\"error\": f\"Failed to parse arguments: {str(e)}\"}\n",
    "    except KeyError as e:\n",
    "        return {\"error\": f\"Missing argument: {str(e)}\"}\n",
    "    except PermissionError as e:\n",
    "        return {\"error\": f\"Permission error: {str(e)}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408f6465",
   "metadata": {},
   "source": [
    "# Step 2: üîÑ Agent Loop\n",
    "\n",
    "Now build the iterative loop that powers your coding agent! This is where the LLM reasons, calls tools, receives results, and decides what to do next.\n",
    "\n",
    "- üéØ **Goal:** Implement a multi-step agent that iterates until task completion or max steps\n",
    "- üîÅ **Workflow:** Create a loop that alternates between LLM calls and tool execution\n",
    "- üí° **Remember:** Use max_steps to prevent infinite loops, and stop when the LLM doesn't call any functions\n",
    "- üí° **Tip:** Use the JupyterAI chatbot with the **prompt examples below**\n",
    "- üìé **Attach these files:** `project.ipynb` and `docs.md` when asking the chatbot for help\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Your agent loop should include:\n",
    "\n",
    "- ‚úì Message history that accumulates conversation context\n",
    "- ‚úì LLM API calls with developer system prompt, messages, and tool schemas\n",
    "- ‚úì Processing of response parts (text messages and function calls)\n",
    "- ‚úì Tool execution and result injection back into conversation\n",
    "- ‚úì Stopping conditions (max steps or no function calls)\n",
    "\n",
    "---\n",
    "\n",
    "<details>\n",
    "<summary><strong>üìö Refresher: Agent Loop Pattern (click to expand)</strong></summary>\n",
    "\n",
    "The agent follows this cycle:\n",
    "\n",
    "1. **Send query** to LLM with system prompt and conversation history\n",
    "2. **Process response** - check if LLM wants to call tools\n",
    "3. **Execute tools** - run functions and add results to conversation\n",
    "4. **Repeat** until LLM responds without tool calls or max_steps reached\n",
    "\n",
    "**Why an agent loop?**\n",
    "- Enables multi-step reasoning and tool use\n",
    "- Allows the LLM to see tool results and adapt its strategy\n",
    "- Prevents infinite loops with max_steps safeguard\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>üìö Refresher: Key Components (click to expand)</strong></summary>\n",
    "\n",
    "**Message History:**\n",
    "```python\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Create a function that adds two numbers\"},\n",
    "    # LLM responses and tool results get appended here\n",
    "]\n",
    "```\n",
    "\n",
    "**Stopping Conditions:**\n",
    "- `steps >= max_steps`: Prevent infinite loops\n",
    "- `not has_function_call`: LLM finished reasoning\n",
    "\n",
    "**Function Call Result:**\n",
    "```python\n",
    "{\n",
    "    \"type\": \"function_call_output\",\n",
    "    \"call_id\": part.call_id,\n",
    "    \"output\": json.dumps(result)\n",
    "}\n",
    "```\n",
    "\n",
    "**Loop structure:**\n",
    "```python\n",
    "for step in range(max_steps):\n",
    "    # 1. Call LLM\n",
    "    response = client.responses.create(...)\n",
    "    \n",
    "    # 2. Process response parts\n",
    "    for part in response.output:\n",
    "        # Append to messages\n",
    "        # Execute function calls\n",
    "    \n",
    "    # 3. Check if done\n",
    "    if not has_function_call:\n",
    "        break\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "üìå **Tip:** Test with simple queries first, then try multi-step tasks!\n",
    "\n",
    "---\n",
    "\n",
    "<details>\n",
    "<summary><strong>üìä Prompt Example ‚Äî Data Analyzer Agent Loop (click to expand)</strong></summary>\n",
    "\n",
    "```\n",
    "You are my coding assistant. Generate Python code to implement the agent loop for my Data Analyzer Agent.\n",
    "Return code only-no explanations, comments, or markdown.\n",
    "\n",
    "Requirements:\n",
    "1. Define coding_agent(client: OpenAI, query: str, system: str, tools: dict, tools_schemas: list, messages: list = None, max_steps: int = 5)\n",
    "2. Initialize messages list with user query if not provided\n",
    "3. Create while loop that runs up to max_steps iterations\n",
    "4. Call client.responses.create() with model=\"gpt-4.1-mini\", developer role with system prompt, messages, and tools\n",
    "5. Iterate over response.output parts and append to messages\n",
    "6. For message parts, print the content\n",
    "7. For function_call parts, execute the tool and append function_call_output to messages with call_id and JSON output\n",
    "8. Track has_function_call flag and break loop if no function calls\n",
    "9. Return final messages list\n",
    "\n",
    "**Attachments:**\n",
    "- `docs.md` for E2B + OpenAI documentation\n",
    "- `project.ipynb` to see the progress of my project\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>üåê Prompt Example ‚Äî Web Builder Agent Loop (click to expand)</strong></summary>\n",
    "\n",
    "```\n",
    "You are my coding assistant. Generate Python code to implement the agent loop for my Web Builder Agent.\n",
    "Return code only-no explanations, comments, or markdown.\n",
    "\n",
    "Requirements:\n",
    "1. Define coding_agent(client: OpenAI, query: str, system: str, tools: dict, tools_schemas: list, max_steps: int = 5)\n",
    "2. Initialize messages with user query dict\n",
    "3. Create iteration loop with step counter up to max_steps\n",
    "4. Call LLM with developer system prompt, messages history, and tool schemas\n",
    "5. Process each output part: append to messages, print text content, execute function calls\n",
    "6. For each function call, use execute_tool helper and append result with proper structure\n",
    "7. Set has_function_call flag and break if False\n",
    "8. Print step number and tool execution results for debugging\n",
    "9. Return messages after loop completes\n",
    "\n",
    "**Attachments:**\n",
    "- `docs.md` for E2B + OpenAI documentation\n",
    "- `project.ipynb` to see the progress of my project\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>üåê Prompt Example ‚Äî API Integration Agent Loop (click to expand)</strong></summary>\n",
    "\n",
    "```\n",
    "You are my coding assistant. Generate Python code to implement the agent loop for my API Integration Agent.\n",
    "Return code only-no explanations, comments, or markdown.\n",
    "\n",
    "Requirements:\n",
    "1. Define coding_agent(client: OpenAI, query: str, system: str, tools: dict, tools_schemas: list, max_steps: int = 5)\n",
    "2. Initialize messages with user query dict\n",
    "3. Create iteration loop with step counter up to max_steps\n",
    "4. Call LLM with developer system prompt, messages history, and tool schemas\n",
    "5. Process each output part: append to messages, print text content, execute function calls\n",
    "6. For each function call, use execute_tool helper and append result with proper structure\n",
    "7. Set has_function_call flag and break if False\n",
    "8. Print step number and tool execution results for debugging\n",
    "9. Return messages after loop completes\n",
    "\n",
    "**Attachments:**\n",
    "- `docs.md` for E2B + OpenAI documentation\n",
    "- `project.ipynb` to see the progress of my project\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50f06439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coding_agent(client: OpenAI, query: str, system: str, tools: dict, tools_schemas: list, max_steps: int = 5):\n",
    "    messages = [{\"role\": \"user\", \"content\": query}]\n",
    "    for step in range(max_steps):\n",
    "        print(f\"[Step {step}] Running agent...\")\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            input=[{\"role\": \"developer\", \"content\": system}, *messages],\n",
    "            tools=tools_schemas\n",
    "        )\n",
    "\n",
    "        has_function_call = False\n",
    "\n",
    "        for part in response.output:\n",
    "            messages.append(part.to_dict())\n",
    "\n",
    "            if part.type == \"message\":\n",
    "                print(f\"[Agent] {part.content}\")\n",
    "\n",
    "            elif part.type == \"function_call\":\n",
    "                has_function_call = True\n",
    "                print(f\"[Tool call] {part.name} with args: {part.arguments}\")\n",
    "                result = execute_tool(part.name, part.arguments, tools)\n",
    "                print(f\"[Tool result] {json.dumps(result, indent=2)}\")\n",
    "\n",
    "                messages.append({\n",
    "                    \"type\": \"function_call_output\",\n",
    "                    \"call_id\": part.call_id,\n",
    "                    \"output\": json.dumps(result)\n",
    "                })\n",
    "\n",
    "        if not has_function_call:\n",
    "            print(\"[Agent] No more function calls. Stopping.\")\n",
    "            break\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46794197",
   "metadata": {},
   "source": [
    "# Step 3: ‚òÅÔ∏è Sandbox Execution\n",
    "\n",
    "Finally, move your agent to the cloud! Instead of running code locally, execute everything in an E2B sandbox‚Äîa secure, isolated environment perfect for untrusted code.\n",
    "\n",
    "- üéØ **Goal:** Integrate E2B sandbox with your coding agent for safe cloud execution\n",
    "- üîÅ **Workflow:** Create sandbox, modify execute_code to use sandbox, update agent to pass sandbox to tools\n",
    "- üí° **Remember:** Sandboxes are persistent‚Äîyou can reconnect, query by metadata, and serve websites from them\n",
    "- üí° **Tip:** Use the JupyterAI chatbot with the **prompt examples below**\n",
    "- üìé **Attach these files:** `project.ipynb` and `docs.md` when asking the chatbot for help\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Your sandbox integration should include:\n",
    "\n",
    "- ‚úì Sandbox creation with appropriate timeout\n",
    "- ‚úì Modified execute_code function that uses `sbx.run_code()`\n",
    "- ‚úì Metadata handling for images and visualizations\n",
    "- ‚úì Agent function updated to accept and pass sandbox parameter\n",
    "- ‚úì Test execution with sample query\n",
    "\n",
    "---\n",
    "\n",
    "<details>\n",
    "<summary><strong>üìö Refresher: E2B Sandbox Features (click to expand)</strong></summary>\n",
    "\n",
    "E2B provides secure cloud sandboxes with these capabilities:\n",
    "\n",
    "1. **Isolated execution** - Code runs in secure microVM\n",
    "2. **File system** - Create, read, write, delete files\n",
    "3. **Multiple languages** - Python, JavaScript, Bash\n",
    "4. **Web hosting** - Serve applications on custom ports\n",
    "5. **Persistent** - Reconnect to existing sandboxes by ID\n",
    "\n",
    "**Why use sandboxes?**\n",
    "- Execute untrusted LLM-generated code safely\n",
    "- Avoid polluting your local environment\n",
    "- Access pre-installed packages and tools\n",
    "- Serve web applications with public URLs\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>üìö Refresher: Sandbox Integration (click to expand)</strong></summary>\n",
    "\n",
    "**Create Sandbox:**\n",
    "```python\n",
    "sbx = Sandbox.create(timeout=60 * 60)  # 1 hour\n",
    "```\n",
    "\n",
    "**Execute Code:**\n",
    "```python\n",
    "execution = sbx.run_code(\"print('Hello')\")\n",
    "result = execution.to_json()\n",
    "```\n",
    "\n",
    "**Handle Results:**\n",
    "```python\n",
    "# Access stdout/stderr\n",
    "print(execution.results)\n",
    "\n",
    "# Access images (PNG data)\n",
    "for result in execution.results:\n",
    "    if result.png:\n",
    "        # Store base64 PNG data\n",
    "        png_data = result.png\n",
    "```\n",
    "\n",
    "**Modified Agent Pattern:**\n",
    "```python\n",
    "def coding_agent(..., sbx: Sandbox):\n",
    "    # Pass sandbox to execute_tool\n",
    "    result = execute_tool(name, args, tools, sbx=sbx)\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "üìå **Tip:** Test with a simple task first, then try complex multi-step projects!\n",
    "\n",
    "---\n",
    "\n",
    "<details>\n",
    "<summary><strong>üìä Prompt Example ‚Äî Data Analyzer Sandbox (click to expand)</strong></summary>\n",
    "\n",
    "```\n",
    "You are my coding assistant. Generate Python code to integrate E2B sandbox with my Data Analyzer Agent.\n",
    "Return code only-no explanations, comments, or markdown.\n",
    "\n",
    "Requirements:\n",
    "1. Import display and Image from IPython.display, and import base64\n",
    "2. Modify execute_code function to accept sbx: Sandbox parameter\n",
    "3. Replace exec() with sbx.run_code(code) and capture execution object\n",
    "4. Handle execution.results and execution.error\n",
    "5. For results with PNG data, store in metadata dict and set result.png = None\n",
    "6. Return execution.to_json() and metadata dict as tuple\n",
    "7. Define execute_code_schema (same as before, LLM doesn't know about sbx parameter)\n",
    "8. Update execute_tool to pass sbx=sbx kwarg to tools\n",
    "9. Update coding_agent to accept sbx parameter and pass it to execute_tool\n",
    "10. Create test: sbx = Sandbox.create(timeout=3600), run agent with query \"Generate 50 random numbers and plot histogram\"\n",
    "11. After agent completes, decode and display images: for each png_data in metadata[\"images\"], use display(Image(data=base64.b64decode(png_data))) to convert the base64 string from E2B to binary data for IPython\n",
    "\n",
    "**Attachments:**\n",
    "- `docs.md` for E2B + OpenAI documentation\n",
    "- `project.ipynb` to see the progress of my project\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>üåê Prompt Example ‚Äî Web Builder Sandbox (click to expand)</strong></summary>\n",
    "\n",
    "```\n",
    "You are my coding assistant. Generate Python code to integrate E2B sandbox with my Web Builder Agent and serve the result.\n",
    "Return code only-no explanations, comments, or markdown.\n",
    "\n",
    "Requirements:\n",
    "1. Import display and IFrame from IPython.display, and import time\n",
    "2. Modify execute_code to use sbx.run_code() instead of local exec()\n",
    "3. Return execution.to_json() and metadata dict as tuple\n",
    "4. Define execute_code_schema (same as before, LLM doesn't know about sbx parameter)\n",
    "5. Modify execute_tool to pass sbx to all tool functions\n",
    "6. Update coding_agent signature to include sbx: Sandbox parameter\n",
    "7. Create sandbox with Sandbox.create(timeout=3600)\n",
    "8. Define system prompt: \"You are a web development agent. You MUST use execute_code to write all files to /home/user/ directory using Python code with open(). Never return code as text - always execute Python to write files.\"\n",
    "9. Run agent with query \"Create a simple calculator app with HTML/CSS/JS in index.html\"\n",
    "10. After agent completes, start HTTP server in /home/user directory: sbx.commands.run(\"cd /home/user && python -m http.server 3000 --bind 0.0.0.0\", background=True)\n",
    "11. Wait 3 seconds for server to start: time.sleep(3)\n",
    "12. Get host URL with sbx.get_host(3000)\n",
    "13. Use display(IFrame(f\"https://{host}\", width=800, height=600)) to render the calculator in notebook output\n",
    "\n",
    "**Attachments:**\n",
    "- `docs.md` for E2B + OpenAI documentation\n",
    "- `project.ipynb` to see the progress of my project\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>üåê Prompt Example ‚Äî API Integration Sandbox (click to expand)</strong></summary>\n",
    "\n",
    "```\n",
    "You are my coding assistant. Generate Python code to integrate E2B sandbox with my API Integration Agent.\n",
    "Return code only-no explanations, comments, or markdown.\n",
    "\n",
    "Requirements:\n",
    "1. Import modules\n",
    "2. Modify execute_code function to accept sbx: Sandbox parameter\n",
    "3. Replace exec() with sbx.run_code(code) and capture execution object\n",
    "4. Handle execution.results and execution.error\n",
    "5. Return execution.to_json() and metadata dict as tuple\n",
    "6. Define tool schemas (same as before, LLM doesn't know about sbx parameter)\n",
    "7. Update execute_tool to pass sbx=sbx kwarg to tools\n",
    "8. Update coding_agent to accept sbx parameter and pass it to execute_tool\n",
    "9. Define system prompt: \"\"\"\n",
    "You are an autonomous API integration agent.\n",
    "You are given a task, an API base URL, an optional API key.\n",
    "You may explore API documentation, call API endpoints, write client code in order to complete the task.\n",
    "Rules:\n",
    "- Only call tools when necessary\n",
    "- [IMPORTANT] When you have enough information, respond with:\n",
    "  FINAL: <human-readable answer>\\\n",
    "- Do not call tools after FINAL\n",
    "- If needed, you can get today's date by calling ```datetime.today().strftime('%Y-%m-%d')```\n",
    ")\n",
    "\"\"\"\n",
    "10. Create test: sbx = Sandbox.create(timeout=3600), run agent with query \"Fetch today's weather forecast for the city of Patras, Greece using 'https://api.open-meteo.com/v1/forecast' API. No API key needed\"\n",
    "11. Display the weather forecast in human readable form\n",
    "\n",
    "**Attachments:**\n",
    "- `docs.md` for E2B + OpenAI documentation\n",
    "- `project.ipynb` to see the progress of my project\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4edd40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 0] Running agent...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tool call] execute_code => {\"code\":\"from datetime import datetime\\n\\ntoday_date = datetime.today().strftime('%Y-%m-%d')\\ntoday_date\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tool result] \"{\\\"results\\\": [{\\\"text\\\": \\\"2026-01-16\\\"}], \\\"logs\\\": \\\"{\\\\\\\"stdout\\\\\\\": [], \\\\\\\"stderr\\\\\\\": []}\\\", \\\"error\\\": null}\"\n",
      "[Step 1] Running agent...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent] [ResponseOutputText(annotations=[], text=\"Today's date is 2026-01-16. I will now call the 'https://api.open-meteo.com/v1/forecast' API to fetch the weather forecast for Patras, Greece for today.\", type='output_text', logprobs=[])]\n",
      "[Tool call] execute_code => {\"code\":\"import requests\\n\\nlatitude = 38.2442\\nlongitude = 21.7346\\nstart_date = '2026-01-16'\\nend_date = '2026-01-16'\\n\\nurl = 'https://api.open-meteo.com/v1/forecast'\\nparams = {\\n    'latitude': latitude,\\n    'longitude': longitude,\\n    'start_date': start_date,\\n    'end_date': end_date,\\n    'daily': 'temperature_2m_max,temperature_2m_min,precipitation_sum,weathercode',\\n    'timezone': 'Europe/Athens'\\n}\\n\\nresponse = requests.get(url, params=params)\\nresponse.json()\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tool result] \"{\\\"results\\\": [{\\\"text\\\": \\\"{'latitude': 38.25,\\\\n 'longitude': 21.75,\\\\n 'generationtime_ms': 0.09107589721679688,\\\\n 'utc_offset_seconds': 7200,\\\\n 'timezone': 'Europe/Athens',\\\\n 'timezone_abbreviation': 'GMT+2',\\\\n 'elevation': 20.0,\\\\n 'daily_units': {'time': 'iso8601',\\\\n  'temperature_2m_max': '\\\\u00b0C',\\\\n  'temperature_2m_min': '\\\\u00b0C',\\\\n  'precipitation_sum': 'mm',\\\\n  'weathercode': 'wmo code'},\\\\n 'daily': {'time': ['2026-01-16'],\\\\n  'temperature_2m_max': [13.6],\\\\n  'temperature_2m_min': [10.3],\\\\n  'precipitation_sum': [0.0],\\\\n  'weathercode': [3]}}\\\", \\\"json\\\": {\\\"latitude\\\": 38.25, \\\"longitude\\\": 21.75, \\\"generationtime_ms\\\": 0.09107589721679688, \\\"utc_offset_seconds\\\": 7200, \\\"timezone\\\": \\\"Europe/Athens\\\", \\\"timezone_abbreviation\\\": \\\"GMT+2\\\", \\\"elevation\\\": 20.0, \\\"daily_units\\\": {\\\"time\\\": \\\"iso8601\\\", \\\"temperature_2m_max\\\": \\\"\\\\u00b0C\\\", \\\"temperature_2m_min\\\": \\\"\\\\u00b0C\\\", \\\"precipitation_sum\\\": \\\"mm\\\", \\\"weathercode\\\": \\\"wmo code\\\"}, \\\"daily\\\": {\\\"time\\\": [\\\"2026-01-16\\\"], \\\"temperature_2m_max\\\": [13.6], \\\"temperature_2m_min\\\": [10.3], \\\"precipitation_sum\\\": [0.0], \\\"weathercode\\\": [3]}}}], \\\"logs\\\": \\\"{\\\\\\\"stdout\\\\\\\": [], \\\\\\\"stderr\\\\\\\": []}\\\", \\\"error\\\": null}\"\n",
      "[Step 2] Running agent...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent] [ResponseOutputText(annotations=[], text='The weather forecast for Patras, Greece on 2026-01-16 is as follows:\\n- Maximum temperature: 13.6 ¬∞C\\n- Minimum temperature: 10.3 ¬∞C\\n- Precipitation sum: 0.0 mm (no rain)\\n- Weather code: 3 (partly cloudy)\\n\\nFINAL: The weather in Patras, Greece today is expected to be partly cloudy with temperatures ranging from 10.3 ¬∞C to 13.6 ¬∞C and no precipitation.', type='output_text', logprobs=[])]\n",
      "[Agent] No more function calls. Stopping.\n",
      "\n",
      "[Result] Agent messages:\n",
      "[{'annotations': [], 'text': \"Today's date is 2026-01-16. I will now call the 'https://api.open-meteo.com/v1/forecast' API to fetch the weather forecast for Patras, Greece for today.\", 'type': 'output_text', 'logprobs': []}]\n",
      "[{'annotations': [], 'text': 'The weather forecast for Patras, Greece on 2026-01-16 is as follows:\\n- Maximum temperature: 13.6 ¬∞C\\n- Minimum temperature: 10.3 ¬∞C\\n- Precipitation sum: 0.0 mm (no rain)\\n- Weather code: 3 (partly cloudy)\\n\\nFINAL: The weather in Patras, Greece today is expected to be partly cloudy with temperatures ranging from 10.3 ¬∞C to 13.6 ¬∞C and no precipitation.', 'type': 'output_text', 'logprobs': []}]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from e2b_code_interpreter import Sandbox\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def execute_code(code: str, sbx: Sandbox):\n",
    "    metadata = {}\n",
    "    execution = sbx.run_code(code)\n",
    "    if execution.error:\n",
    "        return {\"results\": [], \"errors\": [execution.error]}, metadata\n",
    "    return execution.to_json(), metadata\n",
    "\n",
    "execute_code_schema = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"execute_code\",\n",
    "    \"description\": \"Execute Python code and return the result or error\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"code\": {\"type\": \"string\", \"description\": \"Python code to execute\"}\n",
    "        },\n",
    "        \"required\": [\"code\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "def write_file(content: str, file_path: str, sbx: Sandbox):\n",
    "    try:\n",
    "        sbx.files.write(file_path, content)\n",
    "        return {\"results\": [f\"File written to {file_path}\"], \"errors\": []}, {}\n",
    "    except Exception as e:\n",
    "        return {\"results\": [], \"errors\": [str(e)]}, {}\n",
    "\n",
    "write_file_schema = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"write_file\",\n",
    "    \"description\": \"Write file to sandbox path\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"content\": {\"type\": \"string\", \"description\": \"File content\"},\n",
    "            \"file_path\": {\"type\": \"string\", \"description\": \"File path in sandbox\"}\n",
    "        },\n",
    "        \"required\": [\"content\", \"file_path\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "tools = {\"execute_code\": execute_code, \"write_file\": write_file}\n",
    "\n",
    "def execute_tool(name: str, args: str, tools: dict, sbx: Sandbox):\n",
    "    try:\n",
    "        parsed_args = json.loads(args)\n",
    "        if name not in tools:\n",
    "            return {\"error\": f\"Tool {name} not found.\"}, {}\n",
    "        return tools[name](**parsed_args, sbx=sbx)\n",
    "    except json.JSONDecodeError as e:\n",
    "        return {\"error\": f\"Failed to parse arguments: {str(e)}\"}, {}\n",
    "    except KeyError as e:\n",
    "        return {\"error\": f\"Missing argument: {str(e)}\"}, {}\n",
    "    except PermissionError as e:\n",
    "        return {\"error\": f\"Permission error: {str(e)}\"}, {}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}, {}\n",
    "\n",
    "def coding_agent(client: OpenAI, sbx: Sandbox, query: str, system: str, tools: dict, tools_schemas: list, max_steps: int = 5):\n",
    "    messages = [{\"role\": \"user\", \"content\": query}]\n",
    "    for step in range(max_steps):\n",
    "        print(f\"[Step {step}] Running agent...\")\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            input=[{\"role\": \"developer\", \"content\": system}, *messages],\n",
    "            tools=tools_schemas\n",
    "        )\n",
    "        has_function_call = False\n",
    "        for part in response.output:\n",
    "            messages.append(part.to_dict())\n",
    "            if part.type == \"message\":\n",
    "                print(f\"[Agent] {part.content}\")\n",
    "                if \"FINAL:\" in part.content:\n",
    "                    return messages\n",
    "            elif part.type == \"function_call\":\n",
    "                has_function_call = True\n",
    "                print(f\"[Tool call] {part.name} => {part.arguments}\")\n",
    "                result, metadata = execute_tool(part.name, part.arguments, tools, sbx)\n",
    "                print(f\"[Tool result] {json.dumps(result, indent=2)}\")\n",
    "                messages.append({\n",
    "                    \"type\": \"function_call_output\",\n",
    "                    \"call_id\": part.call_id,\n",
    "                    \"output\": json.dumps(result)\n",
    "                })\n",
    "        if not has_function_call:\n",
    "            print(\"[Agent] No more function calls. Stopping.\")\n",
    "            break\n",
    "    return messages\n",
    "\n",
    "system = \"\"\"\n",
    "You are an autonomous API integration agent.\n",
    "You are given a task, an API base URL, an optional API key.\n",
    "You may explore API documentation, call API endpoints, write client code in order to complete the task.\n",
    "Rules:\n",
    "- Only call tools when necessary\n",
    "- [IMPORTANT] When you have enough information, respond with:\n",
    "  FINAL: <human-readable answer>\\\n",
    "- Do not call tools after FINAL\n",
    "- If needed, you can get today's date by calling ```datetime.today().strftime('%Y-%m-%d')```\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "sbx = Sandbox.create(timeout=3600)\n",
    "\n",
    "query = \"Fetch today's weather forecast for the city of Patras, Greece using 'https://api.open-meteo.com/v1/forecast' API. No API key needed\"\n",
    "\n",
    "messages = coding_agent(client, sbx, query, system, tools, [execute_code_schema, write_file_schema])\n",
    "\n",
    "print(\"\\n[Result] Agent messages:\")\n",
    "for msg in messages:\n",
    "    if msg.get(\"role\") == \"assistant\" or (msg.get(\"type\") == \"message\" and \"FINAL:\" in msg.get(\"content\", \"\")):\n",
    "        print(msg.get(\"content\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dd866c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéâ Congratulations!\n",
    "\n",
    "You've completed your coding agent project! You've learned how to:\n",
    "\n",
    "‚úÖ Define tool schemas and execution functions for LLM function calling  \n",
    "‚úÖ Implement an agent loop with conversation memory and iterative reasoning  \n",
    "‚úÖ Integrate E2B sandboxes for safe cloud code execution  \n",
    "‚úÖ Handle tool results and build multi-step autonomous agents  \n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Want to extend your project? Try:\n",
    "- Adding more tools (file operations, web scraping, API calls)\n",
    "- Implementing conversation memory persistence across sessions\n",
    "- Creating specialized agents for different domains (data science, web dev, DevOps)\n",
    "- Building multi-agent systems where agents collaborate on complex tasks\n",
    "\n",
    "---\n",
    "\n",
    "> ‚ö†Ô∏è **Final Reminder:** Your workspace session lasts 2 hours. Download `project.ipynb` now to save your work!\n",
    "\n",
    "---\n",
    "\n",
    "**Resources:**\n",
    "- [E2B Documentation](https://e2b.dev/docs)\n",
    "- [OpenAI Function Calling Guide](https://platform.openai.com/docs/guides/function-calling)\n",
    "- [E2B GitHub](https://github.com/e2b-dev/e2b)\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Optional Feedback Survey\n",
    "\n",
    "We'd love to hear about your experience! Your feedback helps us create more valuable educational experiences.\n",
    "\n",
    "**[Take the short survey ‚Üí](https://rebrand.ly/e2b-course)**\n",
    "\n",
    "This optional survey asks about:\n",
    "- Project quality and engagement\n",
    "- What you found most valuable\n",
    "- How we can improve future projects\n",
    "\n",
    "Thank you for your time! üôè"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
